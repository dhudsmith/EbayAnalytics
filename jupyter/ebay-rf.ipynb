{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to demonstrate the basic application of a random forest (RF) classifier to the prediction of the sales outcome of ebay listings of Apple Macbook Pro laptop computers. This analysis is based on approximately 45,000 historical listings extracted using the ebay Finding API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-04T14:08:08.956638",
     "start_time": "2016-05-04T14:08:08.805930"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, classification_report\n",
    "import pprint as pp\n",
    "\n",
    "# Read in the pandas.DataFrame from csv\n",
    "data = pd.read_csv('../Data/ebay_data_rf.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest (RF) makes sense in this application for a number of reasons:\n",
    "1. The ebay features are almost all categorical. RF handles categorical variables without too much extra effort (as compared with SVM).\n",
    "2. There are significant feature interactions. For example, the impact of item cost on sales outcome depends strongly on whether the listing is auction or fixed-price. RF models can 'learn' feature interactions quite robustly.\n",
    "3. Though RFs must be refit to incorporate new observations, they fit relatively quickly (under average circumstances). They also predict quite quickly. \n",
    "\n",
    "Nevertheless, RF models do pose some problems in this application:\n",
    "1. It's possible (though I've tried to minimize this) that several features are correlated. Though I don't at present understand why, I've read that RF has difficulty with correlated features. Perhaps they increase the variance in the model fit?\n",
    "2. Ultimately, we would like to make recommendations to ebay sellers based on the model outputs. Though RF can rank feature importances (as we will see below), making interpretations based on these rankings is notoriously dicey. This is a problem with many models, though.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-04T14:08:09.027652",
     "start_time": "2016-05-04T14:08:08.958894"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Separate target variable from inputs\n",
    "y = data.sellingState\n",
    "X = data.drop('sellingState', axis=1)\n",
    "\n",
    "# Split test and train\n",
    "test_frac = 0.25\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_frac, random_state=7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-04T14:08:22.858642",
     "start_time": "2016-05-04T14:08:09.029925"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight={0: 1, 1: 1},\n",
       "            criterion='gini', max_depth=None, max_features=10,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators = 200\n",
    "max_features = 10\n",
    "weights = {0: 1, 1: 1}\n",
    "clf = RandomForestClassifier(n_estimators = n_estimators,\n",
    "                             max_features=max_features,\n",
    "                             class_weight=weights,\n",
    "                             warm_start=False)\n",
    "\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-04T14:08:23.979244",
     "start_time": "2016-05-04T14:08:22.860393"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[8604  255]\n",
      " [1113 1238]]\n",
      "Normalized confusion matrix:\n",
      " [[ 0.76752899  0.02274755]\n",
      " [ 0.09928635  0.11043711]]\n",
      "Accuracy:\n",
      " 0.877966101695\n",
      "ROC AUC:\n",
      " 0.874567909201\n"
     ]
    }
   ],
   "source": [
    "# Test on the training set:\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix\n",
    "mat = confusion_matrix(y_test, y_test_pred)\n",
    "num = np.sum(mat)\n",
    "print(\"Confusion matrix:\\n\", mat)\n",
    "print(\"Normalized confusion matrix:\\n\", mat/num)\n",
    "print(\"Accuracy:\\n\", (mat[0,0]+mat[1,1])/num)\n",
    "\n",
    "# Calculate the roc_auc score\n",
    "print('ROC AUC:\\n', roc_auc_score(y_test, clf.predict_proba(X_test)[:,1], average = 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy on the test set agrees well with the OOB error rate of about 0.2 for our model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importances\n",
    "The random forest model also allows us to see which features were important for modeling the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-04T14:08:24.021805",
     "start_time": "2016-05-04T14:08:23.980697"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Features    Scores\n",
      "14            feedbackScore  0.227047\n",
      "17                    value  0.178777\n",
      "18                  endHour  0.108629\n",
      "6         buyItNowAvailable  0.080699\n",
      "1           productId_value  0.072083\n",
      "19               endWeekday  0.068454\n",
      "15  positiveFeedbackPercent  0.047489\n",
      "10             shippingType  0.034556\n",
      "13       feedbackRatingStar  0.028292\n",
      "3               conditionId  0.023150\n",
      "2      conditionDisplayName  0.019597\n",
      "9         expeditedShipping  0.018833\n",
      "12          returnsAccepted  0.018745\n",
      "5               listingType  0.018109\n",
      "16           topRatedSeller  0.015588\n",
      "7          bestOfferEnabled  0.014506\n",
      "0            productId_type  0.010552\n",
      "11           isShippingFree  0.010055\n",
      "4                   country  0.002934\n",
      "8             paymentMethod  0.001907\n"
     ]
    }
   ],
   "source": [
    "cols = X.columns\n",
    "feature_scores = clf.feature_importances_\n",
    "\n",
    "score_card = pd.DataFrame.from_items([('Features', cols),('Scores', feature_scores)])\n",
    "score_card.sort_values(by = 'Scores', inplace=True, ascending=False)\n",
    "\n",
    "print(score_card)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the most important features have to do with the time of day that the listing started and ended and the day of month that the listing started and ended. These variables are may be highly correlated, so we should be careful not to read too much into the model at this point. We can say, however, that listing time features are predictive for the listing outcome."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
